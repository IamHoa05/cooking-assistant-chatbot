# app/core/search_engine.py
"""
Search Engine cho m√≥n ƒÉn d·ª±a tr√™n nguy√™n li·ªáu:
- K·∫øt h·ª£p FAISS (embedding + cosine similarity)
- Fuzzy matching, exact match, Jaccard
- Score t·ªïng h·ª£p cho ranking cu·ªëi c√πng
"""

import os
import yaml
import numpy as np
import pandas as pd
import unicodedata
from difflib import get_close_matches
import ast

from ..utils.faiss_handler import FAISSHandler
from ..utils.embedder import load_embedding_model, embed_texts

# ===========================================
# 1. Load config
# ===========================================
CONFIG_PATH = os.path.abspath(
    os.path.join(os.path.dirname(__file__), "../../config.yml")
)
with open(CONFIG_PATH, "r", encoding="utf-8") as f:
    CONFIG = yaml.safe_load(f)

EMBED_MODEL_NAME = CONFIG["embedding"]["model_name"]
EMBED_BATCH_SIZE = CONFIG["embedding"].get("batch_size", 32)

# ===========================================
# 2. Helper functions
# ===========================================
def clean_ingredient(text: str) -> str:
    """
    Chu·∫©n h√≥a nguy√™n li·ªáu:
    - lowercase
    - lo·∫°i b·ªè d·∫•u
    - strip kho·∫£ng tr·∫Øng
    """
    text = text.lower().strip()
    text = ''.join(c for c in unicodedata.normalize('NFD', text)
                   if unicodedata.category(c) != 'Mn')
    return text

def parse_ingredient_list(val):
    """
    Parse t·ª´ list/str trong DataFrame th√†nh list string.
    """
    if isinstance(val, list):
        return val
    if isinstance(val, str):
        try:
            return ast.literal_eval(val)
        except Exception:
            return [val]
    return []

def canonicalize_ingredient_list(col):
    """
    Chu·∫©n h√≥a c·ªôt ingredient_names:
    - convert string ‚Üí list
    - strip + lowercase t·ª´ng ph·∫ßn t·ª≠
    """
    result = []

    for x in col:
        if isinstance(x, list):
            val = [v.strip().lower() for v in x if isinstance(v, str) and v.strip()]
            result.append(val)
            continue

        if isinstance(x, str):
            x = x.strip()
            if not x:
                result.append([])
                continue
            try:
                parsed = ast.literal_eval(x)
                if isinstance(parsed, list):
                    val = [v.strip().lower() for v in parsed if isinstance(v, str) and v.strip()]
                    result.append(val)
                    continue
            except:
                pass
            val = [v.strip().lower() for v in x.split(",") if v.strip()]
            result.append(val)
            continue

        result.append([])
    return result

def fuzzy_match(recipe_ings, input_ings, cutoff=0.8):
    """
    T√≠nh t·ª∑ l·ªá fuzzy match gi·ªØa nguy√™n li·ªáu recipe v√† input.
    """
    recipe_ings = parse_ingredient_list(recipe_ings)
    recipe_clean = [clean_ingredient(i) for i in recipe_ings]
    input_clean = [clean_ingredient(i) for i in input_ings]

    matched = 0
    for ing in input_clean:
        close = get_close_matches(ing, recipe_clean, n=1, cutoff=cutoff)
        if close:
            matched += 1
    return matched / len(input_ings) if input_ings else 0

def compute_scores(recipe_ing, query_ing):
    """
    T√≠nh exact match & Jaccard score.
    """
    recipe_set = set(recipe_ing)
    query_set = set(query_ing)
    exact = len(recipe_set & query_set) / len(query_set) if query_set else 0
    jaccard = len(recipe_set & query_set) / len(recipe_set | query_set) if recipe_set else 0
    return exact, jaccard

# ===========================================
# 3. Main search function
# ===========================================
def search_dishes(df, handler, input_ingredients, top_faiss=100, top_k=5):
    """
    T√¨m m√≥n ƒÉn d·ª±a tr√™n embedding + FAISS + fuzzy/exact/Jaccard scoring.
    """
    # Encode input ingredients th√†nh vector
    model = load_embedding_model(EMBED_MODEL_NAME)
    query_vec = embed_texts(input_ingredients, model, batch_size=EMBED_BATCH_SIZE)
    query_vec = np.mean(query_vec, axis=0)

    # Search top_faiss m√≥n trong FAISS
    results = handler.search(query_vec=query_vec, column_key="names", top_k=top_faiss)

    # T√≠nh score chi ti·∫øt cho ranking
    for r in results:
        exact, jaccard = compute_scores(r["ingredient_names"], input_ingredients)
        fuzzy = fuzzy_match(r["ingredient_names"], input_ingredients)
        r["exact_match"] = exact
        r["jaccard"] = jaccard
        r["fuzzy_match"] = fuzzy

        r["final_score"] = (
            r["_distance"] * 0.7 +
            exact * 0.15 +
            jaccard * 0.1 +
            fuzzy * 0.05
        )

        matched_count = sum(1 for ing in input_ingredients if ing in r["ingredient_names"])
        if matched_count >= 1:
            bonus = 0.05 * min(matched_count, 4)
            r["final_score"] *= (1 + bonus)

    # Sort & l·∫•y top_k
    final_results = sorted(results, key=lambda x: x["final_score"], reverse=True)[:top_k]

    # Format k·∫øt qu·∫£ tr·∫£ v·ªÅ
    formatted_results = []
    for r in final_results:
        matched_count = sum(1 for ing in input_ingredients if ing in r["ingredient_names"])
        formatted_results.append({
            "dish_name": r["dish_name"],
            "ingredients": r["ingredient_names"],
            "final_score": round(r["final_score"], 4),
            "score_breakdown": {
                "cosine": round(r["_distance"], 4),
                "exact_match": round(r["exact_match"], 4),
                "jaccard": round(r["jaccard"], 4),
                "fuzzy": round(r["fuzzy_match"], 4),
                "matched_count": matched_count
            }
        })

    return formatted_results

# ===========================================
# 4. Engine initialization
# ===========================================
def initialize_search_engine(
    data_path=os.path.abspath(os.path.join(os.path.dirname(__file__), "../utils/data/recipes_embeddings.pkl")),
    index_dir=os.path.abspath(os.path.join(os.path.dirname(__file__), "../utils/faiss_indexes"))
):
    """
    Load DataFrame v√† FAISSHandler, chu·∫©n h√≥a c·ªôt ingredient_names.
    """
    df = pd.read_pickle(data_path)
    df["ingredient_names"] = canonicalize_ingredient_list(df["ingredient_names"])

    handler = FAISSHandler(df, index_dir=index_dir)
    return df, handler

def search_by_ingredients(input_ingredients, df, handler, top_k=5):
    """
    Wrapper: x·ª≠ l√Ω input string ‚Üí list + search.
    """
    if isinstance(input_ingredients, str):
        input_ingredients = [x.strip().lower() for x in input_ingredients.split(",") if x.strip()]
    return search_dishes(df, handler, input_ingredients, top_k=top_k)

# ===========================================
# 5. Example usage
# ===========================================
if __name__ == "__main__":
    df, handler = initialize_search_engine()
    user_input = "·ª©c g√†, b·∫Øp c·∫£i, khoai t√¢y, c√† r·ªët, b√≠ ƒë·ªè"
    results = search_by_ingredients(user_input, df, handler, top_k=5)

    print(f"üîç K·∫øt qu·∫£ t√¨m ki·∫øm cho: {user_input}")
    print("="*60)
    for i, r in enumerate(results, 1):
        print(f"{i}. {r['dish_name']} | Score: {r['final_score']:.4f}")
        print(f"   Nguy√™n li·ªáu: {', '.join(r['ingredients'])}")
        print(f"   Chi ti·∫øt: Cosine={r['score_breakdown']['cosine']:.3f}, "
              f"Exact={r['score_breakdown']['exact_match']:.3f}, "
              f"Jaccard={r['score_breakdown']['jaccard']:.3f}, "
              f"Fuzzy={r['score_breakdown']['fuzzy']:.3f}")
        print()
