# import pandas as pd
# import numpy as np
# from faiss_handler import FAISSHandler
# from embedder import load_vietnamese_embedding_model, embed_texts

# if __name__ == "__main__":
#     # 1. Load DataFrame th·∫≠t ƒë√£ embed
#     print("üöÄ Loading DataFrame...")
#     df = pd.read_pickle("./data/recipes_embeddings.pkl")

#     # 2. Map key ‚Üí t√™n c·ªôt embedding
#     embedding_columns = {
#         "names": "ingredient_names_embedding",
#         "quantities": "ingredient_quantities_embedding",
#         "dish": "dish_name_embedding",
#     }

#     # 3. Load FAISS handler
#     print("üîç Loading FAISS indexes...")
#     handler = FAISSHandler(df=df, embedding_columns=embedding_columns, index_dir="./faiss_indexes")
#     print("‚úÖ FAISS handler loaded!")

#     # 4. Nh·∫≠p danh s√°ch nguy√™n li·ªáu t·ª´ user
#     user_input = input("üí¨ Nh·∫≠p danh s√°ch nguy√™n li·ªáu (ngƒÉn c√°ch b·∫±ng d·∫•u ph·∫©y):\nüëâ Ingredients: ")
#     ingredients = [x.strip() for x in user_input.split(",") if x.strip()]
    
#     # 5. Load embedding model
#     print("üß† Loading embedding model (BAAI/bge-base-en-v1.5)...")
#     model = load_vietnamese_embedding_model(device="cpu")

#     # 6. Encode input nguy√™n li·ªáu (query)
#     print("\nüîß Encoding ingredients...")
#     query_vecs = embed_texts([", ".join(ingredients)], model, text_type="query")
#     query_vec = np.array(query_vecs[0]).astype("float32")

#     # 7. Search FAISS
#     print(f"üîé Searching FAISS index ({embedding_columns['names']})...\n")
#     results = handler.search(query_vector=query_vec, column_key="names", top_k=5)

#     # 8. In k·∫øt qu·∫£
#     print("\n==============================")
#     print("üçΩÔ∏è TOP RESULTS:")
#     for i, r in enumerate(results, 1):
#         print(f"{i}. Dish: {r.get('dish_name')}  | distance = {r['_distance']:.4f}")
#         print(f"   Ingredients: {r.get('ingredient_names')}")


# import pandas as pd
# import numpy as np
# from faiss_handler import FAISSHandler
# from embedder import load_vietnamese_embedding_model, embed_texts
# from collections import defaultdict

# if __name__ == "__main__":
#     print("üöÄ Loading DataFrame...")
#     df = pd.read_pickle("./data/recipes_embeddings.pkl")
#     # print(df.columns)
#     embedding_columns = {
#         "names": "ingredient_names_embedding",
#         "quantities": "ingredient_quantities_embedding",
#         "dish": "dish_name_embedding",
#     }

#     print("üîç Loading FAISS indexes...")
#     handler = FAISSHandler(df=df, embedding_columns=embedding_columns, index_dir="./faiss_indexes")
#     print("‚úÖ FAISS handler loaded!")

#     user_input = input("üí¨ Nh·∫≠p danh s√°ch nguy√™n li·ªáu (ngƒÉn c√°ch b·∫±ng d·∫•u ph·∫©y):\nüëâ Ingredients: ")
#     ingredients = [x.strip() for x in user_input.split(",") if x.strip()]

#     print("üß† Loading embedding model (BAAI/bge-base-en-v1.5)...")
#     model = load_vietnamese_embedding_model(device="cpu")

#     print("\nüîß Encoding t·ª´ng nguy√™n li·ªáu...")
#     ingredient_vecs = embed_texts(ingredients, model, text_type="query")
#     ingredient_vecs = [np.array(v).astype("float32") for v in ingredient_vecs]

#     print(f"\nüîé Searching FAISS index for t·ª´ng nguy√™n li·ªáu...\n")

#     # üëâ Score aggregator
#     score_map = defaultdict(float)
#     count_map = defaultdict(int)

#     for ing, vec in zip(ingredients, ingredient_vecs):
#         print(f"\nüîπ T√¨m theo nguy√™n li·ªáu: {ing}")
#         results = handler.search(query_vector=vec, column_key="names", top_k=20)

#         for r in results:
#             row_id = r["__rowid__"]     # üî• index g·ªëc
#             score = -r["_distance"]

#             score_map[row_id] += score
#             count_map[row_id] += 1

#     # üëâ Ranking theo t·ªïng score + s·ªë nguy√™n li·ªáu match
#     ranked = sorted(score_map.items(), key=lambda x: (count_map[x[0]], x[1]), reverse=True)

#     print("\n==============================")
#     print("üçΩÔ∏è TOP RESULTS:")

#     top = 5
#     for i, (row_id, total_score) in enumerate(ranked[:top], 1):
#         row = df.iloc[row_id]   # üî• l·∫•y l·∫°i d√≤ng th·∫≠t

#         print(f"{i}. Dish: {row['dish_name']} | matched {count_map[row_id]}/{len(ingredients)}")
#         print(f"   Ingredients: {row['ingredient_names']}\n")


# # test_faiss_cosine_fuzzy.py
# import pandas as pd
# import numpy as np
# from faiss_handler import FAISSHandler
# from embedder import load_vietnamese_embedding_model, embed_texts
# from collections import defaultdict
# import unicodedata
# from difflib import get_close_matches

# # -----------------------------
# # Helpers
# # -----------------------------
# def clean_ingredient(text):
#     text = text.lower().strip()
#     text = ''.join(c for c in unicodedata.normalize('NFD', text)
#                    if unicodedata.category(c) != 'Mn')
#     return text

# def fuzzy_match(recipe_ings, input_ings, cutoff=0.6):
#     recipe_clean = [clean_ingredient(i) for i in recipe_ings]
#     input_clean = [clean_ingredient(i) for i in input_ings]

#     matched = []
#     for ing in input_clean:
#         close = get_close_matches(ing, recipe_clean, n=1, cutoff=cutoff)
#         if close:
#             matched.append(close[0])
#     match_count = len(matched)
#     match_ratio = match_count / len(input_clean) if input_clean else 0
#     return matched, match_count, match_ratio

# def avg_cosine_score(input_vecs, recipe_vecs):
#     """T√≠nh trung b√¨nh max cosine similarity gi·ªØa c√°c nguy√™n li·ªáu input v√† m√≥n"""
#     scores = []
#     for v_in in input_vecs:
#         sims = [np.dot(v_in, v_rec)/(np.linalg.norm(v_in)*np.linalg.norm(v_rec)) for v_rec in recipe_vecs]
#         scores.append(max(sims))
#     return np.mean(scores)

# # -----------------------------
# # Main search
# # -----------------------------
# def search_dishes_with_cosine_fuzzy(df, handler, input_ingredients, top_faiss=100, top_k=5, alpha=0.7):
#     """
#     T√¨m m√≥n ƒÉn d·ª±a tr√™n cosine similarity + fuzzy match
#     alpha: tr·ªçng s·ªë cosine, 1-alpha: tr·ªçng s·ªë fuzzy
#     """
#     print("üß† Encoding input ingredients...")
#     model = load_vietnamese_embedding_model(device="cpu")
#     input_vecs = embed_texts(input_ingredients, model, text_type="query")
#     input_vecs = [np.array(v).astype("float32") for v in input_vecs]

#     # 1Ô∏è‚É£ FAISS search t·ª´ng nguy√™n li·ªáu ‚Üí g·ªôp score v·ªÅ m√≥n
#     score_map = defaultdict(list)  # idx m√≥n -> list vec c·ªßa nguy√™n li·ªáu m√≥n
#     for vec in input_vecs:
#         results = handler.search(query_vector=vec, column_key="names", top_k=top_faiss)
#         for r in results:
#             idx = r.get("_rowid__") or r.get("index")
#             if idx is not None:
#                 score_map[idx].append(r["_distance"])  # l∆∞u score embedding (cosine)

#     # 2Ô∏è‚É£ T√≠nh score t·ªïng h·ª£p
#     final_results = []
#     for idx, row in df.iloc[list(score_map.keys())].iterrows():
#         # embedding m√≥n
#         recipe_vecs = []
#         ing_embeds = row["ingredient_names_embedding"]
#         if isinstance(ing_embeds, list):
#             for vec in ing_embeds:
#                 recipe_vecs.append(np.array(vec).astype("float32"))
#         if not recipe_vecs:
#             continue

#         score_cosine = avg_cosine_score(input_vecs, recipe_vecs)
#         matched, match_count, match_ratio = fuzzy_match(row['ingredient_names'], input_ingredients)
#         # t·ªïng h·ª£p
#         score_total = alpha*score_cosine + (1-alpha)*match_ratio

#         final_results.append({
#             "dish_name": row['dish_name'],
#             "ingredient_names": row['ingredient_names'],
#             "matched_ingredients": matched,
#             "match_count": match_count,
#             "match_ratio": match_ratio,
#             "score_cosine": score_cosine,
#             "score_total": score_total
#         })

#     # 3Ô∏è‚É£ S·∫Øp x·∫øp theo score_total gi·∫£m d·∫ßn
#     final_results = sorted(final_results, key=lambda x: x["score_total"], reverse=True)

#     return final_results[:top_k]

# # -----------------------------
# # Example usage
# # -----------------------------
# if __name__ == "__main__":
#     df = pd.read_pickle("./data/recipes_embeddings.pkl")
#     print(df.columns)
#     embedding_columns = {
#         "names": "ingredient_names_embedding",
#         "quantities": "ingredient_quantities_embedding",
#         "dish": "dish_name_embedding",
#     }
#     handler = FAISSHandler(df=df, embedding_columns=embedding_columns, index_dir="./faiss_indexes")

#     user_input = input("üí¨ Nh·∫≠p danh s√°ch nguy√™n li·ªáu (ngƒÉn c√°ch b·∫±ng d·∫•u ph·∫©y):\nüëâ Ingredients: ")
#     input_ingredients = [x.strip() for x in user_input.split(",") if x.strip()]

#     results = search_dishes_with_cosine_fuzzy(df, handler, input_ingredients, top_faiss=100, top_k=5, alpha=0.7)

#     print("\n==============================")
#     print("üçΩÔ∏è TOP RESULTS:")
#     for i, r in enumerate(results, 1):
#         print(f"{i}. Dish: {r['dish_name']} | matched {r['match_count']}/{len(input_ingredients)}")
#         print(f"   Ingredients: {r['ingredient_names']}")
#         print(f"   Matched ingredients: {r['matched_ingredients']}")
#         print(f"   Cosine score: {r['score_cosine']:.4f}")
#         print(f"   Total score: {r['score_total']:.4f}\n")


# test_faiss_cosine_fuzzy.py
import pandas as pd
import numpy as np
from faiss_handler import FAISSHandler
from embedder import load_vietnamese_embedding_model, embed_texts
from collections import defaultdict
import unicodedata
from difflib import get_close_matches
import ast

# -----------------------------
# Helpers
# -----------------------------
def clean_ingredient(text):
    """Chu·∫©n h√≥a nguy√™n li·ªáu: lowercase, remove d·∫•u, trim"""
    text = text.lower().strip()
    text = ''.join(c for c in unicodedata.normalize('NFD', text)
                   if unicodedata.category(c) != 'Mn')
    return text

def parse_ingredient_list(val):
    """Chuy·ªÉn string d·∫°ng list th√†nh list th·ª±c s·ª±"""
    if isinstance(val, list):
        return val
    elif isinstance(val, str):
        try:
            return ast.literal_eval(val)
        except Exception:
            return [val]
    return []

def fuzzy_match_debug(recipe_ings, input_ings, cutoff=0.6):
    """
    Fuzzy match v·ªõi debug: tr·∫£ v·ªÅ matched, match_count, match_ratio, matched_pairs
    matched_pairs = list of tuples (input_ing, recipe_ing_matched or None)
    """
    recipe_ings = parse_ingredient_list(recipe_ings)
    recipe_clean = [clean_ingredient(i) for i in recipe_ings]
    input_clean = [clean_ingredient(i) for i in input_ings]

    matched = []
    matched_pairs = []
    for ing_in, ing_clean in zip(input_ings, input_clean):
        close = get_close_matches(ing_clean, recipe_clean, n=1, cutoff=cutoff)
        if close:
            matched.append(close[0])
            matched_pairs.append((ing_in, close[0]))
        else:
            matched_pairs.append((ing_in, None))

    match_count = len(matched)
    match_ratio = match_count / len(input_ings) if input_ings else 0
    return matched, match_count, match_ratio, matched_pairs

def avg_cosine_score(input_vecs, recipe_vecs):
    """T√≠nh trung b√¨nh max cosine similarity gi·ªØa c√°c nguy√™n li·ªáu input v√† m√≥n"""
    scores = []
    for v_in in input_vecs:
        sims = [np.dot(v_in, v_rec)/(np.linalg.norm(v_in)*np.linalg.norm(v_rec)) for v_rec in recipe_vecs]
        scores.append(max(sims))
    return np.mean(scores)

# -----------------------------
# Main search
# -----------------------------
def search_dishes_with_cosine_fuzzy(df, handler, input_ingredients, top_faiss=100, top_k=5, alpha=0.7):
    """
    T√¨m m√≥n ƒÉn d·ª±a tr√™n cosine similarity + fuzzy match
    alpha: tr·ªçng s·ªë cosine, 1-alpha: tr·ªçng s·ªë fuzzy
    """
    print("üß† Encoding input ingredients...")
    model = load_vietnamese_embedding_model(device="cpu")
    input_vecs = embed_texts(input_ingredients, model, text_type="query")
    input_vecs = [np.array(v).astype("float32") for v in input_vecs]

    # 1Ô∏è‚É£ FAISS search t·ª´ng nguy√™n li·ªáu ‚Üí g·ªôp score v·ªÅ m√≥n
    score_map = defaultdict(list)  # idx m√≥n -> list vec embedding m√≥n
    for vec in input_vecs:
        results = handler.search(query_vector=vec, column_key="names", top_k=top_faiss)
        for r in results:
            idx = r.get("_rowid__") or r.get("index")
            if idx is not None:
                score_map[idx].append(r["_distance"])  # cosine similarity

    # 2Ô∏è‚É£ T√≠nh score t·ªïng h·ª£p + fuzzy
    final_results = []
    for idx, row in df.iloc[list(score_map.keys())].iterrows():
        # embedding m√≥n
        recipe_vecs = []
        ing_embeds = row["ingredient_names_embedding"]
        if isinstance(ing_embeds, list):
            for vec in ing_embeds:
                recipe_vecs.append(np.array(vec).astype("float32"))
        if not recipe_vecs:
            continue

        score_cosine = avg_cosine_score(input_vecs, recipe_vecs)
        matched, match_count, match_ratio, matched_pairs = fuzzy_match_debug(row['ingredient_names'], input_ingredients)
        score_total = alpha*score_cosine + (1-alpha)*match_ratio

        # Debug in
        print("\nRecipe raw:", row['ingredient_names'])
        print("Recipe cleaned:", parse_ingredient_list(row['ingredient_names']))
        print("Input cleaned:", [clean_ingredient(i) for i in input_ingredients])
        print("Fuzzy debug pairs (input ‚Üí recipe match):", matched_pairs)
        print("Cosine score:", score_cosine)
        print("Fuzzy match ratio:", match_ratio)
        print("Total score:", score_total)

        final_results.append({
            "dish_name": row['dish_name'],
            "ingredient_names": parse_ingredient_list(row['ingredient_names']),
            "matched_ingredients": matched,
            "match_count": match_count,
            "match_ratio": match_ratio,
            "score_cosine": score_cosine,
            "score_total": score_total
        })

    # 3Ô∏è‚É£ S·∫Øp x·∫øp theo score_total gi·∫£m d·∫ßn
    final_results = sorted(final_results, key=lambda x: x["score_total"], reverse=True)
    return final_results[:top_k]

# -----------------------------
# Example usage
# -----------------------------
if __name__ == "__main__":
    df = pd.read_pickle("./data/recipes_embeddings.pkl")
    embedding_columns = {
        "names": "ingredient_names_embedding",
        "quantities": "ingredient_quantities_embedding",
        "dish": "dish_name_embedding",
    }
    handler = FAISSHandler(df=df, embedding_columns=embedding_columns, index_dir="./faiss_indexes")

    user_input = input("üí¨ Nh·∫≠p danh s√°ch nguy√™n li·ªáu (ngƒÉn c√°ch b·∫±ng d·∫•u ph·∫©y):\nüëâ Ingredients: ")
    input_ingredients = [x.strip() for x in user_input.split(",") if x.strip()]

    results = search_dishes_with_cosine_fuzzy(df, handler, input_ingredients, top_faiss=100, top_k=5, alpha=0.7)

    print("\n==============================")
    print("üçΩÔ∏è TOP RESULTS:")
    for i, r in enumerate(results, 1):
        print(f"{i}. Dish: {r['dish_name']} | matched {r['match_count']}/{len(input_ingredients)}")
        print(f"   Ingredients: {r['ingredient_names']}")
        print(f"   Matched ingredients: {r['matched_ingredients']}")
        print(f"   Cosine score: {r['score_cosine']:.4f}")
        print(f"   Total score: {r['score_total']:.4f}\n")
