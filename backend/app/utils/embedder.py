# # from sentence_transformers import SentenceTransformer
# # from tqdm import tqdm
# # import pandas as pd
# # import torch


# # def load_vietnamese_embedding_model(device: str = None):
# #     """
# #     Load embedding model with GPU support if available.
# #     """
# #     model_name = "paraphrase-multilingual-MiniLM-L12-v2"
# #     print(f"ðŸ”¹ Loading model: {model_name}")

# #     if device is None:
# #         device = "cuda" if torch.cuda.is_available() else "cpu"

# #     model = SentenceTransformer(model_name, device=device)
# #     print(f"ðŸ‘‰ Using device: {device}")

# #     return model


# # def embed_texts(texts, model: SentenceTransformer, batch_size=64):
# #     """
# #     Encode texts efficiently with GPU + normalization.
# #     """
# #     return model.encode(
# #         texts,
# #         batch_size=batch_size,
# #         show_progress_bar=True,
# #         convert_to_tensor=False,  # Ä‘á»ƒ lÆ°u pickle dá»…
# #         normalize_embeddings=True # embedding chuáº©n hÃ³a â†’ tá»‘t cho kNN / cosine
# #     )


# # def generate_vietnamese_recipe_embeddings(df: pd.DataFrame):

# #         model = load_vietnamese_embedding_model()
        
# #         columns_to_embed = {
# #             "ingredient_names": "ingredient_names_embedding",
# #             "ingredient_quantities": "ingredient_quantities_embedding",
# #             "dish_name": "dish_name_embedding"
# #         }

# #         for text_col, out_col in columns_to_embed.items():
# #             print(f"Embedding column: {text_col}")
# #             texts = df[text_col].fillna("").astype(str).tolist()

# #             vectors = embed_texts(texts, model, batch_size=32)  # numpy array (n, 384)

# #             # Fix chÃ­nh xÃ¡c:
# #             vectors_list = [v.tolist() for v in vectors]  # má»—i row lÃ  list 384 float
# #             df[out_col] = pd.Series(vectors_list, dtype=object)

# #         return df



# # if __name__ == "__main__":
# #     df = pd.read_csv("./data/test_processed_recipes.csv")

# #     df_emb = generate_vietnamese_recipe_embeddings(df)

# #     output = "./data/recipes_embeddings.pkl"
# #     df_emb.to_pickle(output)
# #     print(f"âœ… Saved embeddings to {output}")


# from sentence_transformers import SentenceTransformer
# from tqdm import tqdm
# import pandas as pd
# import torch
# from typing import List, Union


# def load_vietnamese_embedding_model(device: str = None):
#     """
#     Load BGE embedding model with GPU support.
#     """
#     # ðŸ”¥ Model BGE cho tiáº¿ng Viá»‡t (nÃªn dÃ¹ng)
#     model_name = "BAAI/bge-base-en-v1.5"   # hoáº·c "dinhnguyenhv/bge-vi-base" náº¿u báº¡n cÃ³ báº£n VI-FT
#     print(f"ðŸ”¹ Loading BGE model: {model_name}")

#     if device is None:
#         device = "cuda" if torch.cuda.is_available() else "cpu"

#     model = SentenceTransformer(model_name, device=device)
#     print(f"ðŸ‘‰ Using device: {device}")

#     return model


# # def embed_texts(texts, model: SentenceTransformer, batch_size=64):
# #     """
# #     Encode texts using BGE + normalization.
# #     LÆ¯U Ã: BGE khuyáº¿n nghá»‹ dÃ¹ng normalize_embeddings=True cho cosine + FAISS.
# #     """
# #     # Vá»›i BGE, Ä‘á»ƒ káº¿t quáº£ Ä‘Ãºng, pháº£i thÃªm prefix "query: " hoáº·c "passage: " (tÃ¹y task)
# #     # NhÆ°ng á»Ÿ Ä‘Ã¢y báº¡n Ä‘ang encode dá»¯ liá»‡u (passages) â†’ dÃ¹ng prefix "passage: "
# #     prefixed = [f"passage: {t}" for t in texts]

# #     return model.encode(
# #         prefixed,
# #         batch_size=batch_size,
# #         show_progress_bar=True,
# #         convert_to_tensor=False,
# #         normalize_embeddings=True
# #     )

# def embed_text(text: str, model: SentenceTransformer, text_type: str = "passage") -> List[float]:
#     """
#     Táº¡o embedding cho má»™t chuá»—i duy nháº¥t sá»­ dá»¥ng mÃ´ hÃ¬nh BGE.
#     Tá»± Ä‘á»™ng thÃªm prefix ('passage' hoáº·c 'query') vÃ  chuáº©n hÃ³a embedding.
    
#     Args:
#         text: Chuá»—i cáº§n embed.
#         model: MÃ´ hÃ¬nh SentenceTransformer (BGE).
#         text_type: Loáº¡i text, 'passage' (máº·c Ä‘á»‹nh) hoáº·c 'query'.
    
#     Returns:
#         List[float]: Vector embedding Ä‘Ã£ chuáº©n hÃ³a.
#     """
#     # ThÃªm prefix theo loáº¡i text
#     prefix = f"{text_type}: "
    
#     # Encode text, normalize embedding Ä‘á»ƒ dÃ¹ng cho cosine similarity hoáº·c FAISS
#     embedding = model.encode(
#         [prefix + text], 
#         show_progress_bar=False, 
#         normalize_embeddings=True
#     )
    
#     # Tráº£ vá» vector dáº¡ng list
#     return embedding[0].tolist()


# def embed_texts(texts: List[str], model: SentenceTransformer, batch_size: int = 32, text_type: str = "passage") -> List[List[float]]:
#     """
#     Táº¡o embedding cho danh sÃ¡ch nhiá»u chuá»—i sá»­ dá»¥ng mÃ´ hÃ¬nh BGE theo batch.
#     Tá»± Ä‘á»™ng thÃªm prefix ('passage' hoáº·c 'query') vÃ  chuáº©n hÃ³a embedding.
    
#     Args:
#         texts: Danh sÃ¡ch cÃ¡c chuá»—i cáº§n embed.
#         model: MÃ´ hÃ¬nh SentenceTransformer (BGE).
#         batch_size: Sá»‘ lÆ°á»£ng text má»—i batch (máº·c Ä‘á»‹nh 32).
#         text_type: Loáº¡i text, 'passage' (máº·c Ä‘á»‹nh) hoáº·c 'query'.
    
#     Returns:
#         List[List[float]]: Danh sÃ¡ch cÃ¡c vector embedding Ä‘Ã£ chuáº©n hÃ³a.
#     """
#     # ThÃªm prefix cho táº¥t cáº£ cÃ¡c text
#     prefix = f"{text_type}: "
#     prefixed_texts = [prefix + t for t in texts]
    
#     embeddings = []
    
#     # Encode theo tá»«ng batch
#     for i in tqdm(range(0, len(prefixed_texts), batch_size)):
#         batch = prefixed_texts[i:i + batch_size]
        
#         # Encode batch, normalize embeddings
#         batch_embeddings = model.encode(
#             batch, 
#             show_progress_bar=False, 
#             normalize_embeddings=True
#         )
        
#         # LÆ°u káº¿t quáº£
#         embeddings.extend(batch_embeddings)
    
#     # Chuyá»ƒn sang list of list
#     return [emb.tolist() for emb in embeddings]

# def generate_vietnamese_recipe_embeddings(df: pd.DataFrame):
#     model = load_vietnamese_embedding_model()
    
#     columns_to_embed = {
#         "ingredient_names": "ingredient_names_embedding",
#         "ingredient_quantities": "ingredient_quantities_embedding",
#         "dish_name": "dish_name_embedding"
#     }

#     for text_col, out_col in columns_to_embed.items():
#         print(f"Embedding column: {text_col}")
#         texts = df[text_col].fillna("").astype(str).tolist()

#         # Gá»i embed_texts 1 láº§n, tráº£ vá» list of list
#         vectors = embed_texts(texts, model, batch_size=32)  # List[List[float]]

#         # Trá»±c tiáº¿p lÆ°u list vÃ o DataFrame, khÃ´ng cáº§n .tolist()
#         df[out_col] = pd.Series(vectors, dtype=object)

#     return df



# if __name__ == "__main__":
#     df = pd.read_csv("./data/test_recipes_501_1000_remove_null.csv")

#     df_emb = generate_vietnamese_recipe_embeddings(df)

#     output = "./data/recipes_embeddings.pkl"
#     df_emb.to_pickle(output)
#     print(f"âœ… Saved embeddings to {output}")


from sentence_transformers import SentenceTransformer
from tqdm import tqdm
import pandas as pd
import torch
from typing import List


def load_vietnamese_embedding_model(device: str = None):
    """
    Load BGE embedding model with GPU support.
    """
    model_name = "BAAI/bge-base-en-v1.5"   # hoáº·c báº£n fine-tuned tiáº¿ng Viá»‡t náº¿u cÃ³
    print(f"ðŸ”¹ Loading BGE model: {model_name}")

    if device is None:
        device = "cuda" if torch.cuda.is_available() else "cpu"

    model = SentenceTransformer(model_name, device=device)
    print(f"ðŸ‘‰ Using device: {device}")

    return model


def embed_texts(texts: List[str], model: SentenceTransformer, batch_size: int = 32, text_type: str = "passage") -> List[List[float]]:
    """
    Encode danh sÃ¡ch text báº±ng BGE + normalize embeddings.
    text_type: 'passage' cho dá»¯ liá»‡u gá»‘c, 'query' cho input user.
    """
    prefix = f"{text_type}: "
    prefixed_texts = [prefix + t for t in texts]

    embeddings = []
    for i in tqdm(range(0, len(prefixed_texts), batch_size)):
        batch = prefixed_texts[i:i + batch_size]
        batch_embeddings = model.encode(
            batch,
            show_progress_bar=False,
            normalize_embeddings=True
        )
        embeddings.extend(batch_embeddings)

    return [emb.tolist() for emb in embeddings]


def generate_vietnamese_recipe_embeddings(df: pd.DataFrame):
    """
    Táº¡o embeddings cho tá»«ng cá»™t:
    - ingredient_names: embed tá»«ng nguyÃªn liá»‡u riÃªng láº»
    - ingredient_quantities: embed cáº£ cá»™t náº¿u cáº§n
    - dish_name: embed tÃªn mÃ³n
    """
    model = load_vietnamese_embedding_model()

    # 1. Embed dish_name
    print("Embedding column: dish_name")
    df['dish_name_embedding'] = embed_texts(
        df['dish_name'].fillna("").astype(str).tolist(),
        model,
        batch_size=32,
        text_type="passage"
    )

    # 2. Embed ingredient_names
    print("Embedding column: ingredient_names (tá»«ng nguyÃªn liá»‡u)")
    ingredient_embeddings_list = []

    for ing_list in tqdm(df['ingredient_names'], desc="Processing ingredient_names"):
        if isinstance(ing_list, str):
            # Náº¿u nguyÃªn liá»‡u chÆ°a convert thÃ nh list, giáº£ sá»­ tÃ¡ch bá»Ÿi dáº¥u pháº©y
            ing_list = [x.strip() for x in ing_list.split(",") if x.strip()]
        elif not isinstance(ing_list, list):
            ing_list = []

        # Embed tá»«ng nguyÃªn liá»‡u riÃªng láº»
        if ing_list:
            vecs = embed_texts(ing_list, model, batch_size=16, text_type="passage")
        else:
            vecs = []

        ingredient_embeddings_list.append(vecs)

    df['ingredient_names_embedding'] = pd.Series(ingredient_embeddings_list, dtype=object)

    # 3. Optionally embed ingredient_quantities náº¿u muá»‘n
    print("Embedding column: ingredient_quantities")
    df['ingredient_quantities_embedding'] = embed_texts(
        df['ingredient_quantities'].fillna("").astype(str).tolist(),
        model,
        batch_size=32,
        text_type="passage"
    )

    return df


if __name__ == "__main__":
    # Load CSV
    df = pd.read_csv("./data/test_recipes_501_1000_remove_null.csv")

    # Táº¡o embeddings
    df_emb = generate_vietnamese_recipe_embeddings(df)

    # LÆ°u DataFrame
    output = "./data/recipes_embeddings.pkl"
    df_emb.to_pickle(output)
    print(f"âœ… Saved embeddings to {output}")
